\documentclass{article}
\usepackage{ijcai11}
\usepackage{lipsum}
\usepackage{mathptmx}
\usepackage[scaled=.90]{helvet}
\usepackage{courier}
\usepackage{latexsym} 
\usepackage{environ}

\makeatletter
\newsavebox{\measure@tikzpicture}
\NewEnviron{scaletikzpicturetowidth}[1]{%
  \def\tikz@width{#1}%
  \def\tikzscale{1}\begin{lrbox}{\measure@tikzpicture}%
  \BODY
  \end{lrbox}%
  \pgfmathparse{#1/\wd\measure@tikzpicture}%
  \edef\tikzscale{\pgfmathresult}%
  \BODY
}
\makeatother

\usepackage{todonotes} 
\usepackage{hyperref} 
\usepackage{amsmath} 
\usepackage{float} 
\usepackage{graphicx}
\graphicspath{{graphics/}}
\usepackage[dutch]{babel} 

%visuals
\graphicspath{{visuals/}}
\usepackage{pgfplots}
\pgfplotsset{width=0.45\textwidth,compat=1.5}

\title{Internet of Things code deployment metrics}
\author{
  Ward Schodts\\
  \texttt{ward.schodts@student.kuleuven.be}
  \\[3ex]
  \textbf{Xavier Go\'as Aguililla}\\
  \texttt{xavier.goas@student.kuleuven.be}
}

\begin{document}

\maketitle

% \listoftodos
\linespread{1.3}
\begin{abstract}
Wij stellen een simpele vuistregel voor die kan dienen om te beslissen of een
bepaald stuk applicatielogica op een mote kan draaien zonder lokaal energie- of
performantieverlies, evenals een tool die deze kan nagaan. Deze gebruikt de
kennis van de programmeur en een aantal basiseigenschappen van het te draaien
programma om deze beslissing te maken. We geven ook een aanzet tot het breder en
preciezer toepassen van de technieken waarmee de vuistregel tot stand is gekomen.
  
\end{abstract}

\section{Situering \& probleemstelling}

\subsection{Onderzoeksvraag}

Een typische mote\footnote{Voor een breder overzicht van WSNs, zie
\cite{akyildiz2002wireless}} heeft erg beperkte reken- en opslagcapaciteit, wat
verhindert dat er meerdere processen op effici\"ente wijze concurrent kunnen
worden uitgevoerd. In het algemeen gaat men daarom een simpele strategie
toepassen voor dataverwerking, waarbij de mote \'e\'en enkele
verantwoordelijkheid heeft, het zgn. 'sense and send': sensordata wordt op de
motes niet bewerkt, maar meteen doorgestuurd naar de backend voor verdere
verwerking, waardoor de rol van de motes bij het verwerken van de data
geminimaliseerd wordt.

Dit is de na\"iefste aanpak die men kan gebruiken, en steunt net op het deel van
mote dat het gulzigst is met energie: de antenne.  De vraag dringt zich op: is
er geen manier om van de weliswaar beperkte rekenkracht van de motes gebruik te
maken om effici\"enter om te springen met de antenne? En is het mogelijk een
simpele, algemene maatstaf te gebruiken om te beslissen of dit in een specifiek
deployment scenario kan of niet?

Energie-effici\"entie is een cruciale factor op alle niveaus bij het ontwikkelen
van wireless sensor networks: een typische mote heeft geen toegang tot een
onbeperkte stroombron en moet het doen met een batterij. Deze batterij kan in
veel scenario's waarin WSNs worden gebruikt ook niet hernieuwd
worden,\footnote{Een leuk scenario waarin deze constraint geldt, vindt men bij
\cite{mainwaring2002wireless}} en dus is de levensduur van de mote ook
afhankelijk van hoe zuinig hij omspringt met energie. Het is dan ook geen wonder
dat veel research in het gebied rechtstreeks wordt be\"invloed door deze
kwestie: van de ontwikkeling van besturingssystemen voor motes over
netwerkprotocollen tot studies van netwerktopologie\"en.

Het ontwikkelen van een eenvoudige metric die een programmeur toelaat om snel en
efficiënt te evalueren of een bepaalde applicatie op een mote kan gedeployed
worden of niet zou interessant zijn voor het ontwikkelen van
energie-effici\"ente IoT-systemen. Bovendien zou daarmee een waardevolle
bijdrage kunnen geleverd worden over het ontwikkelen van IoT-architecturen in
het algemeen.

\subsection{Onderzoeksopgave}

Een eenvoudige vuistregel, die:
\begin{itemize}
\item In de grote meerderheid van de gevallen een juiste beslissing zal maken;
\item eenvoudig te integreren is in de ontwikkelingscyclus;
\item semi-automatisch werkt.
\end{itemize}

\section{Voorgestelde oplossing}
We vertrekken vanuit de veronderstelling dat de ontwikkelaar een stuk
applicatielogica rechtstreeks op de motes wilt deployen. Vanuit deze optiek
maken we abstractie van de low-level details van simulatie e.d., en gebruiken we
in plaats daarvan een eenvoudige vuistregel (\textit{code deployment
metric}. Deze geeft een makkelijke ja/nee-beslissing die zegt of we kunnen
deployen of niet. We defini\"eren een functie $h$ voor deze vuistregel als
volgt:
% \begin{equation}
%   \begin{split}
%     h : x \mapsto \{0, 1\} \\
%     h(x) = signum(transmit(x) - cost(reduce(x)) \\ - cost(transmit(reduce(x))))
%   \end{split}
% \end{equation}

\[
h(x)= 
\begin{cases}
  1, & \text{als } tr(x) - cost(red(x)) - cost(tr(red(x))) > 0  \\
  0, & \text{in alle andere gevallen}
\end{cases}
\]

Waarbij $n$ de grootte van de sensordata in bytes is, en $m$ de verwachte
grootte van de output van de functie compute toegepast op de sensorinput, ook in
bytes.

Wat deze ongelijkheid afweegt is: gegeven een reductie van de sensordata van $n$ naar
$m$ bytes, is de som van de kost van deze reductie op een input van een bepaalde
grootte en de kost van het verzenden van de output van deze reductie kleiner dan
de kost van het verzenden van de originele input?

De aard van deze reductie ligt niet vast. In eerste instantie zouden we kunnen
denken aan een louter computationeel proces dat het aantal over te dragen bytes
reduceert en dan meteen overdraagt. Zo'n voorbeeld is een filter: we sturen een
meting pas door als die verschilt van de vorige verstuurde meting. Maar we
kunnen evengoed de sensordata aggregeren in het geheugen, zodat de transferkost
wanneer een meting binnenkomt nul wordt, behalve als de buffer waarin we data
opslaan vol is.\footnote{Merk ook op dat de kost van het verzenden van gegevens
niet lineair is -- er is geen garantie dat $cost(transfer(x)) +
cost(transfer(y)) = cost(transfer(x + y))$. In een keer $x + y$ bytes versturen
kan dus voordeliger uitkomen dan $x$ en $y$ bytes apart te verzenden.} 
Ook een combinatie van beide is mogelijk: we kunnen bijvoorbeeld de buffer
comprimeren door reeksen identieke metingen samen te nemen (filter +
aggregator). Dit zou theoretisch gezien een grotere winst moeten opleveren.

De aandachtige lezer stelt zich meteen de vraag: hoe kunnen wij de kost van zo'n
reductie in het algemeen schatten? We laten de programmeur, die zijn programma
goed kent, ingrijpen. We nemen als input niet enkel het gecompileerde programma,
maar ook een aantal parameters. Deze zijn bijvoorbeeld:

\paragraph{Sensoren.} Hoe groot is de sensordata? Hoe vaak komt er sensordata binnen?
\paragraph{Geheugenverbruik.} Worden er gegevens bijgehouden in een buffer? Hoeveel? Hoe vaak wordt er naar die buffer geschreven?
\paragraph{Nauwkeurigheid.} Wat is de gewenste granulariteit van de metingen,
d.w.z. hoe groot mag het interval tussen twee doorgestuurde metingen zijn?
\paragraph{Tijdsinformatie.} Hoe vaak wordt er data verzonden?
\paragraph{Kostfunctie.} Hoeveel kost de reductie aan CPU-tijd?
\paragraph{Reductiegrootte.} Hoe sterk verkleint de reductie het aantal te
verzenden bytes?

\section{Methodologie}

De kwestie is nu om wat we theoretisch uiteen hebben gezet in te vullen met
empirische data: hoe berekenen wij de kost van het verzenden en verwerken van
gegevens concreet? We berekenen het kostenplaatje \textit{atomisch}: we kiezen
bepaalde eenheden voor de drie componenten van het energieverbruik die we kunnen
be\"invloeden:

\begin{itemize}
\item \textbf{storage}: hoeveel kost het om $n$ bytes op te slaan in het RAM of
het EEPROM?
\item \textbf{computation}: hoeveel kosten $n$ seconden CPU-tijd?
\item \textbf{transmission}: hoeveel kost het om $n$ bytes te verzenden; hoeveel
kost het om de antenne aan en uit te zetten?
\end{itemize}

Een eerste reflex is om naar de technische fiche van de motes te grijpen. die
zijn dan wel vrij betrouwbaar, maar geven metingen weer die als het ware in een
vacu\"um zijn gedaan: de kost van het draaien van het OS, van het op laten staan
van de antenne in low power listening modus, enz. worden hierin niet
meegerekend. We zijn daarom experimenteel gaan uitzoeken wat de kost was van elk
van deze types.

\subsection{Meetopstelling en materialen}

Voor onze metingen maakten wij gebruik van de AVR Zigduino. Deze werd
aangesloten op een circuit met spanning 6V en stroom 0.04A.

De meetmethode is ontleend aan \cite{hughes2013energy}. Voor het meten van het
energieverbruik gedurende een bepaalde periode maken we gebruik van het volgende
circuit:

\begin{figure}[h]
\centering
\includegraphics[width=9cm]{meetopstelling}
%\caption{De meetopstelling \cite{hughes2013energy}}
\label{fig:meetopstelling}
\end{figure}

De oscilloscoop meet de spanning in het circuit. De weerstand kan aan en uit
worden gezet door de mote door het pin-outsignaal te flippen. Er is enkel stroom
in het circuit verbonden aan de pin-out als het signaal op hoog staat; die
periodes zijn duidelijk af te lezen op de output van oscilloscoop en komen
overeen met de periodes waarin de code waarvan we het energiegebruik willen
kennen wordt uitgevoerd. We kunnen gebruik maken van de wet van Ohm om de
verbruikte stroom in die intervallen te schatten. Daardoor kunnen we met goede
precisie meten hoeveel energie een bepaald stuk code verbruikt.

\subsection{De tool}

\paragraph{Input voor de tool}
De tool is geschreven in Python en volgt een simpel stramien: in de directory
waarin het Contiki-programma staat, moet een parameterbestand in
Python-configuratieformaat worden opgeslagen. Dat zal er ongeveer als volgt
uitzien:

\begin{verbatim}
[sensor]
sensor_data_size = <int n>
sensor_data_frequency = <float f>
[memory]
buffer_used = <bool b>
buffer_size = <int n>
buffer_write_freq = <int n>
[precision]
interval_granularity = <float f>
data_granularity = <float f>
[frequency]
reduction_frequency = <float f>
transmission_frequency = <float f>
reduction_cpu_time = <int n>
[reduction]
from = <int n>
to = <int m>
\end{verbatim}

\paragraph{Parameters schatten.} Sommige van deze parameters liggen niet meteen
voor de hand. Bij deze een aantal manieren die we gebruikt hebben om deze
parameters te schatten:

\subparagraph{Kost van de reductie: CPU-tijd.} Momenteel werken wij aan een
methode om bijna volledig automatisch te bepalen hoeveel CPU-tijd het uitvoeren
van de reductie ongeveer kost. Deze is echter nog niet volledig op punt. Een
andere methode is het gebruik van een fysiek meetapparaat om op een soortgelijke
wijze als bij de energiemetingen te kijken hoe lang het duurt voor de reductie
uitgevoerd is. Dit geeft een harde bovengrens voor de gebruikte CPU-cycli: we
hoeven slechts deze tijd te vermenigvuldigen met de klokfrequentie van de
CPU. Bij de Zigduino is dit 16MHz.

\subparagraph{Reductiegrootte.} De reductiegrootte is vaak
niet op het eerste zicht in te schatten. Een voorbeeld: neem dat wij een
temperatuur- en vochtigheidssensor hebben, en we willen op elk mogelijk moment
weten of het aangenaam of niet aangenaam is waar de mote staat, en we steken dit
in juist één byte. Dan hebben wij de temperatuur (bijv. twee bytes) en de
vochtigheidsgraad (bijv. ook twee bytes) gereduceerd naar \'e\'en byte. Dit
kunnen we zeer gemakkelijk uitwerken.

Maar als we bijvoorbeeld een filter toepassen op onze gegevens, en enkel data
verzenden wanneer we een significant ander resultaat hebben dan bij de vorige
meting, dan wordt de situatie complexer: dan hangt de reductiegrootte af van
bv. hoeveel we willen dat het resultaat van de vorige metingen verschilt voor we
versturen, hoe vaak de temperatuur en vochtigheidsgraad schommelen op die plek
(wat op zich weer afhangt van allerlei factoren in de omgeving), enzoverder.

In zo'n situatie is het aangewezen om een slimmere schatting te maken. Een optie
is om via \textit{sense and send} een steekproef te doen van de temperatuur en
vochtigheidsgraad en hieruit af te leiden hoe sterk de temperatuur en
vochtigheidsgraad zullen oscilleren.

Een andere mogelijkheid is het afschatten van de reductiegrootte door de
worst-case reductiegrootte te bekijken.

\subparagraph{Tijdsinformatie.} Merk op dat in het zonet vermelde geval ook de
tijdsinformatie op een gelijkaardige manier moet worden afgeleid. De frequentie
waarop sensordata binnenkomt kan men makkelijk vinden, de frequentie waarmee die
data verzonden wordt soms niet. 

\subparagraph{Geheugenverbruik, sensoren, precisie.} Deze liggen geheel in de
hand van de programmeur; er zijn echter een aantal edge cases. 

\subsection{Een concreet stappenplan voor deployers}
We mikken erop om het beslissingsproces zo goed mogelijk te integreren in
de ontwikkelingsomgeving van Contiki. Men werkt daar voornamelijk met
\texttt{make}-bestanden. Een typische workflow zou er als volgt moeten uitzien.

\begin{enumerate}
\item Schrijf het gewenste programma.
\item Maak een parameterbestand aan. Schat de parameters zoals hierboven
aangegeven en verwerk ze hierin.
\item Voer het commando \texttt{make eval-metric} uit. Dit brengt een evaluatie
van de metric op gang door middel van de gegeven parameters.
\end{enumerate}

\subsection{Een voorbeeldscenario: temperatuurmetingen}

Stel dat we een opstelling hebben waarbij de mote temperatuurmetingen moet
uitvoeren. Dit gebeurt elke seconde; elke meting is twee bytes groot. De
back-end hoeft echter niet in real time op de hoogte te worden gebracht van deze
metingen, maar heeft genoeg aan \'e\'en stuk temperatuurdata per
minuut. Verschillende strategie\"en bieden zich aan:

\paragraph{Sense and send.} Van zodra een meting binnenkomt sturen we hem door.

\subparagraph{Parameters.} 

\begin{verbatim}
[sensor]
sensor_data_size = 2
sensor_data_frequency = 60
[memory]
buffer_used = False
[frequency]
reduction_frequency = 0
transmission_frequency = 60
reduction_cpu_time = 0
[reduction]
transmit_reduction = 1
data_reduction = 1
\end{verbatim}

\subparagraph{Evaluatie metric.} 1639mJ per tijdseenheid. Hiermee vergelijken we verdere strategie\"en.

\paragraph{Filter.} We sturen een meting pas door als die significant verschilt
van de vorige. (Wat `significant verschillend' inhoudt bepalen we op voorhand.)
In dit scenario gaan we ervan uit dat dit gemiddeld bij \'e\'en op twee metingen
gebeurt.

\subparagraph{Parameters.}
\begin{verbatim}
[sensor]
sensor_data_size = 2
sensor_data_frequency = 60
[memory]
buffer_used = True
buffer_size = 1
buffer_write_frequency = 30
[frequency]
reduction_frequency = 60
transmission_frequency = 1
reduction_cpu_time = praktisch 0
[reduction]
transmit_reduction = 2
data_reduction = 2
\end{verbatim}
\subparagraph{Evaluatie metric.} 819.8mJ per tijdseenheid i.p.v. 1639mJ per tijdseenheid. Deployen op mote.

\paragraph{Aggregator.} We houden de metingen bij in een buffer en sturen elke
minuut alles in \'e\'en keer door.

\subparagraph{Parameters.}
\begin{verbatim}
[sensor]
sensor_data_size = 2
sensor_data_frequency = 60
[memory]
buffer_used = True
buffer_size = 120
buffer_write_frequency = 60
[frequency]
reduction_frequency = 60
transmission_frequency = 1
reduction_cpu_time = praktisch 0
[reduction]
transmit_reduction = 60
data_reduction = 1
\end{verbatim}
\subparagraph{Evaluatie metric.} 27.33mJ  per tijdseenheid i.p.v. 1639mJ per tijdseenheid. Deployen op mote.

\paragraph{Gemiddelde.} We houden de metingen bij in een buffer en berekenen het
gemiddelde hiervan elke minuut.

\subparagraph{Parameters.}
\begin{verbatim}
[sensor]
sensor_data_size = 2
sensor_data_frequency = 60
[memory]
buffer_used = True
buffer_size = 120
buffer_write_frequency = 60
[frequency]
reduction_frequency = 60
transmission_frequency = 1
reduction_cpu_time = max. 1200 cycli
[reduction]
transmit_reduction = 60
data_reduction = 60
\end{verbatim}

\subparagraph{Evaluatie metric.} 38.15mJ per tijdseenheid i.p.v. 1639mJ per tijdseenheid. Deployen op mote.

\section{Resultaten}

\begin{figure}[h]
\centering
%Ram energy
\begin{scaletikzpicturetowidth}{\columnwidth}
\begin{tikzpicture}[scale=\tikzscale]
\begin{axis}[
	title=Energie in functie van bytes,
	xlabel={Bytes},
	ylabel={Energie $(mJ)$}]
\addplot[
	red,
	domain=0:8196,
	samples=201]
		{8.144E-5 * x };
\end{axis}
\end{tikzpicture}
\end{scaletikzpicturetowidth}
\caption{Energieverbruik schrijven naar RAM}
\label{fig:energieverbruik_ram}
\end{figure}

\begin{figure}[h]
\centering
%Ram time
\begin{scaletikzpicturetowidth}{\columnwidth}
\begin{tikzpicture}[scale=\tikzscale]
\begin{axis}[
    title=Tijd in functie van bytes,
    xlabel={Bytes},
    ylabel={Tijd $(s)$}]
\addplot[
    red,
    domain=0:8196,
    samples=201]
        {3.752E-7 *x -3.773E-6};
\end{axis}
\end{tikzpicture}
\end{scaletikzpicturetowidth}
\caption{Tijdsduur schrijven naar RAM}
\label{fig:tijdsduur_ram}
\end{figure}

\begin{figure}[h]
\centering
%Energie idleness + energie ram
\begin{scaletikzpicturetowidth}{\columnwidth}
\begin{tikzpicture}[scale=\tikzscale]
\begin{axis}[
scale only axis,
xlabel={Tijd $(ms)$},
ylabel={Energie $(mJ)$}
]
\addplot[
blue,
domain=0:100,
samples=201,
]
{x/0.000333638186177248 * 8.144E-5 };
\addplot[
red,
domain=0:100,
samples=201,
]
{x * 0.224222886125917 };
\end{axis}
\begin{axis}[
scale only axis,
ymin=0,ymax=300000,
xmin=0,xmax=300000,
xlabel={Bytes geschreven},
axis x line*=top,
hide y axis,
]
\end{axis}
\end{tikzpicture}
\end{scaletikzpicturetowidth}
\caption{Energieverbruik idle vs. verbruik RAM}
\label{fig:energieverbruik_idle_vs_RAM}
\end{figure}

\begin{figure}[h]
\centering
% Idle
\begin{tikzpicture}
\begin{axis}[
title=Energie in functie van tijd,
xmin=0.5,xmax=2,
xlabel={Tijd $(ms)$},
ylabel={Energie $(mJ)$},
]
\addplot[blue] table {cpu1.dat};
\addplot[red] table {cpu2.dat};
\addplot[green] table {cpu3.dat};
\addplot[yellow] table {cpu4.dat};
\addplot[gray] table {cpu5.dat};
\end{axis}
\end{tikzpicture}	
\caption{Energieverbruik met antenne volledig uit}
\label{fig:energieverbruik_antenne_uit}
\end{figure}

\begin{figure}[h]
\centering
%CPU engergie
\begin{tikzpicture}
\begin{axis}[
title=Energie in functie van tijd,
xlabel={Tijd $(ms)$},
ylabel={Energie $(mJ)$}
]
\addplot[
blue,
domain=0:100,
samples=201,
]
{0.0037 * x *1E-3 *6};
\end{axis}
\end{tikzpicture}

\caption{Energieverbruik CPU-cycli}
\label{fig:energieverbruik_cpu}
\end{figure}

\paragraph{Kostmetingen}

Voor kostmetingen zijn we als volgt te werk gegaan:

\begin{enumerate}
\item Een ruwe meting: we schrijven een programma dat beroep doet op een deel
van de mote waarvan we het energieverbruik willen berekenen. Bijvoorbeeld: een
programma dat herhaaldelijk bytes naar een buffer in het RAM. 
\end{enumerate}

\subparagraph{Schrijven naar RAM}

Schrijven naar RAM is haast gratis en is daarom een zeer goede
reductiestrategie. De resultaten zijn te zien op \ref{fig:energieverbruik_ram}.

De reden hiervoor is de aard van RAM. Het is volatiel geheugen, dat voortdurend
moet worden gerefreshed. Schrijfoperaties worden in deze refresh-cycli
ge\"integreerd zodat ze haast gratis zijn. Als bewijs hiervan hebben we het energieverbruik vergeleken met dat van het in low-power listening. 
De vergelijking kan gezien worden in \ref{fig:energieverbruik_idle_vs_RAM}.\\
\\
De x-as geeft aan hoelang dat de mote idle is of hoe lang er bytes geschreven worden naar het RAM geheugen. Aan de hand van \ref{fig:tijdsduur_ram} hebben we kunnen berekenen hoeveel bytes er in een bepaalde tijdsduur worden weggeschreven. Voor $1ms$ is dit ongeveer al 3000 bytes. Vandaar dat, hoewel het misschien lijkt dat naar RAM schrijven een kost heeft, deze kost nooit wordt gehaald aangezien er nooit zoveel bytes ineens gaan worden geschreven. Het grote aantal bytes dat zou geschreven worden staat op de tweede x-as bovenaan \ref{fig:energieverbruik_idle_vs_RAM}. 
\subparagraph{Low-power listening}
Dit is de staat waarin de mote zich nog
\todo{fig en tekst}

\begin{figure}[h]
\centering
%CPU engergie
\begin{tikzpicture}
\begin{axis}[
title=Energie in functie van tijd,
xlabel={Tijd $(ms)$},
ylabel={Energie $(mJ)$}
]
\addplot[
blue,
domain=0:100,
samples=201,
]
{x * 0.224222886125917 };
\end{axis}
\end{tikzpicture}

\caption{Energieverbruik low-power listening}
\label{fig:energieverbruik_lpl}
\end{figure}


\subparagraph{Verzenden en ontvangen}

De kost van het verzenden en ontvangen via het netwerk is vrij groot. Dit is
vooral te wijten aan het aanzetten van de antenne, dat enorm veel energie
opslorpt ten opzichte van al het andere. Het eigenlijke verzenden kost ook meer
dan bijv. CPU of RAM, maar als we de overhead van het opstarten buiten
beschouwing laten, is het nog redelijk. Daardoor is het interessant om de
antenne zo min mogelijk aan te zetten, en te proberen zoveel mogelijk data te
bundelen voor verzending om de overhead tot een minimum te beperken.

Een ander aandachtspunt is dat het niet evenveel kost om te zenden als om te
ontvangen. Hierover moeten we nog een aantal experimenten op punt stellen.

\subparagraph{Basisverbruik}

Het complete basisverbruik is makkelijk te meten. De component op de mote hoeft niets doen, net zoals bij Low-power listening. Het enige verschil nu is dat er expliciet moet gezegd worden dat de antenne uit staat.
De metingen voor dit verbruik zijn te vinden in \ref{fig:energieverbruik_antenne_uit}.

\subparagraph{CPU-cycli}

Onze eerste aanpak was het gebruiken van de AVR-simulator Avrora
\cite{titzer2005avrora} om het aantal CPU-cycli exact te meten en te
vermenigvuldigen met de kost voor CPU-cycli zoals vermeld in de technische
fiche. Dit is technisch echter lastiger dan het op het eerste zicht lijkt.
\\
\\
Om dit op te lossen gebruiken we een bovengrens op de CPU kost. We gaan de uitvoertijd van de component meten en daarna voor de gegeven duur de maximale CPU kracht aanrekenen. Met deze bovengrens wordt er nooit te weinig energie aangerekend, maar ook niet excessief veel. Dit komt doordat het verbruik van de microcontroller op zich relatief zeer laag is. Vanaf dat we de duur van de component hebben kunnen we theoretisch aan de hand van de datasheet dan afleiden van het verbruik van de CPU is, dit zoals te verwachten ook linear \ref{fig:energieverbruik_cpu}.\\
\\
Merk op dat het praktisch niet mogelijk is om dit verbruik met de oscilloscoop te meten.
Dit komt doordat een component bijna nooit zuiver alleen CPU gaat gebruiken maar ook nog geheugentoegang, pins, etc. 
% \subsection{Voorbeeldscenario: werkt de metric?}

\section{Verder werk.} 

We hebben al een aantal fundamentele zaken behandeld in deze paper. We kunnen
echter verder gaan.
 
\subparagraph{Volledige netwerktopologie\"en.}

Stel dat de vuistregel voor een bepaalde stuk applicatielogica beslist dat het
best niet op een mote wordt gedeployed. Dan kan het zijn dat deze beslissing met
een krappe marge is genomen. Bijvoorbeeld: we zitten met sensordata van telkens
20B, sturen met dezelfde frequentie als \textit{sense and send} data door, maar
passen telkens een reductie toe waardoor we 10B winnen. De reductie is
betrekkelijk duur, duurder dan het verzenden van 10B, waardoor de heuristiek
aangeeft dat deployen op de mote geen goed idee is. 

Als we echter kennis hebben van de topologie van het netwerk, kunnen we verder
redeneren. Die 20B die we verzenden als we het advies van de metric volgen
moeten immers via een aantal hops de back-end bereiken, en bij elke hop moeten
die 20B opnieuw doorgestuurd worden. Dat betekent dat we als we globaal over
heel het netwerk kijken, het kleine energieverlies dat we boeken bij het
reduceren van 20B naar 10B mogelijk gecompenseerd wordt door wat we winnen aan
verzendkosten over alle hops.

Wat zich hier aanbiedt is een manier om uit onze eenvoudige metric een nieuwe
metric te induceren die de topologie exploiteert om lokale energieverliezen om
te zetten in globale energiewinst. Verdere formalisatie van deze intu\"itie en
experimenten zijn aangewezen.

\subparagraph{Een pessimistische metric.}

Zoals het er nu voor staat hebben we een metric die erg eenvoudig is. Daarin
berust zijn nut, maar stelt hij de zaak niet te simpel voor? Kunnen we de metric
verfijnen en onverwachte overhead in rekening brengen? 



% \subparagraph{Onvoorziene overhead.}

\subparagraph{De \textit{sweet spot} vinden met behulp van kostfuncties.}

Het is eenvoudig in te zien dat in het algemeen er een trade-off optreedt
bij het reduceren van data: verzenden wordt goedkoper, maar we betalen een kost
in de vorm van CPU-cycli. Een interessante vraag is dan: kunnen we een
\textit{sweet spot} vinden, waar de gecombineerde kost van verzending en
datareductie minimaal is?

% \begin{figure}[h]
% \centering
% \missingfigure{}
% \caption{Een sweet spot vinden}
% \label{fig:sweet_spot}
% \end{figure}

\section{Conclusie}

We hebben een metric voorgesteld die voldoet aan onze eisen; we hebben ook een
overzicht gegeven van manieren om de kosten die we in de metric gebruiken te
berekenen. Dit wordt allemaal ge\"integreerd in een tool (nog onder
ontwikkeling).

We hebben ook aangetoond dat het vaak mogelijk is om energiewinst te boeken ten
opzichte van \textit{sense and send}, en dat deze winst enigszins
kwantificeerbaar is met behulp van de metric. We ontwikkelden een eenvoudig
formalisme om de winstpunten ten opzichte van \textit{sense and send} te duiden,
dit in de vorm van de parametrisatie die we hebben aangewend voor het
configureren van onze tool.

Tenslotte hebben we een aanzet gegeven tot verdere ontwikkeling van de idee\"en
die in deze paper zijn voorgesteld. We beschouwen onze oorspronkelijke opzet als
geslaagd, maar werken nog naarstig door aan verfijningen.

\bibliographystyle{named}
\nocite{*}
\bibliography{bibliography}

% \newpage
% \appendix
% \section{Data sets}
\end{document}
